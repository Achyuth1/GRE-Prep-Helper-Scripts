{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pds\n",
    "import os\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "columns = [\"Source\", \"Word\", \"Meaning\", \"Usage\", \"Correct\", \"Incorrect\", \"Score\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Enter GRE words into the `Pandas.DataFrame`\n",
    "* Checks if entry has already been made for the same word\n",
    "* To exit the loop give any input of `len(word) < 3`\n",
    "* It is saved after every entry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the source: \n",
      "Source = trivial\n",
      "\n",
      "\n",
      "Enter the Word: protract\n",
      "Enter the Meaning: lengthen in time; cause to be or last longer\n",
      "Enter the Usage: If you have a disagreement with a friend that you continue for weeks and weeks, you are protracting the argument\n",
      "Entry of 'protract' made\n",
      "Current entry count:6\n",
      "\n",
      "Enter the Word: sully\n",
      "Enter the Meaning: make dirty or spotty, as by exposure to air; also used metaphorically\n",
      "Enter the Usage: If you spread false rumors that there's chicken stock in the vegetarian entree at Joe's Diner, you would sully Joe's good reputation\n",
      "Entry of 'sully' made\n",
      "Current entry count:7\n",
      "\n",
      "Enter the Word: foil\n",
      "Enter the Meaning: hinder or prevent (the efforts, plans, or desires) of\n",
      "Enter the Usage: foil your opponent\n",
      "Entry of 'foil' made\n",
      "Current entry count:8\n",
      "\n",
      "Enter the Word: fealty\n",
      "Enter the Meaning: allegiance; the loyalty that citizens owe to their country (or subjects to their sovereign)\n",
      "Enter the Usage: Most school kids pledge their fealty, or allegiance, to the United States of America every morning in homeroom\n",
      "Entry of 'fealty' made\n",
      "Current entry count:9\n",
      "\n",
      "Enter the Word: gentrification\n",
      "Enter the Meaning: the restoration of run-down urban areas by the middle class (resulting in the displacement of low-income residents)\n",
      "Enter the Usage: When a neighborhood goes through gentrification, buildings get makeovers, new businesses open, and many people whoâ€™ve lived there their entire lives must leave because everything gets more expensive\n",
      "Entry of 'gentrification' made\n",
      "Current entry count:10\n",
      "\n",
      "Enter the Word: bonhomie\n",
      "Enter the Meaning: a disposition to be friendly and approachable (easy to talk to)\n",
      "Enter the Usage: ............\n",
      "Entry of 'bonhomie' made\n",
      "Current entry count:11\n",
      "\n",
      "Enter the Word: \n",
      "\n",
      "ENDING THE ENTRY!\n",
      "\n",
      "Word Count in trivial: 11 / 1510\n"
     ]
    }
   ],
   "source": [
    "import pandas as pds\n",
    "import os\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "columns = [\"Source\", \"Word\", \"Meaning\", \n",
    "           \"Usage\", \"Correct\", \"Incorrect\", \"Score\"]\n",
    "\n",
    "def numberOfEntries(df, source):\n",
    "    cond = (df[\"Source\"]==source)\n",
    "    return len(df[\"Word\"][cond])\n",
    "\n",
    "default = \"trivial\"\n",
    "source = input(\"Enter the source: \").lower()\n",
    "if len(source)==0:\n",
    "    source = default.lower()\n",
    "    \n",
    "print(\"Source = %s\\n\\n\"%source)\n",
    "\n",
    "if os.path.exists(\"./dataFrame.p\"):\n",
    "    df = pickle.load(open(\"./dataFrame.p\", \"rb\"))\n",
    "else:\n",
    "    df = pds.DataFrame(columns=columns)\n",
    "\n",
    "while(True):\n",
    "    entry = {\"Source\":source,\n",
    "            \"Correct\":0,\n",
    "            \"Incorrect\":0,\n",
    "            \"Score\":-2.0}\n",
    "    for col in [\"Word\", \"Meaning\", \"Usage\"]:\n",
    "        entry[col] = input(\"Enter the %s: \"%col).lower()\n",
    "        if len(entry[col])<3:\n",
    "            entry = {\"Source\":\"NULL\"}\n",
    "            break\n",
    "    if entry[\"Source\"] != \"NULL\":\n",
    "        cond = (df[\"Word\"] == entry[\"Word\"])\n",
    "        if cond.any():\n",
    "            index = df[cond].index[0]\n",
    "            row = df.iloc[index]\n",
    "            print(\"\\nWord %s exists from %s\\n\\t%s = %s\\n\\tEx: %s\\n\"%(row[\"Word\"], row[\"Source\"], \n",
    "                                                               row[\"Word\"], row[\"Meaning\"], \n",
    "                                                               row[\"Usage\"]))\n",
    "            cmd = input(\"Do you wish to replace? Y/N \").lower()\n",
    "            if cmd=='y':\n",
    "                df.at[index, \"Meaning\"] = entry[\"Meaning\"]\n",
    "                df.at[index, \"Usage\"] = entry[\"Usage\"]\n",
    "                print(\"Modification for %s is done\"%(entry[\"Word\"]))\n",
    "                pickle.dump(df, open(\"./dataFrame.p\", \"wb\"))\n",
    "        else:\n",
    "            df = df.append(entry, ignore_index=True, )\n",
    "            pickle.dump(df, open(\"./dataFrame.p\", \"wb\"))\n",
    "            print(\"Entry of '%s' made\\nCurrent entry count:%d\\n\"%(entry[\"Word\"], numberOfEntries(df, source)))\n",
    "    else:\n",
    "        print(\"\\nEnding the entry!\".upper())\n",
    "        break\n",
    "\n",
    "print(\"\\nWord Count in %s: %d / %d\"%(source, numberOfEntries(df, source), len(df)-2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dictionary implementation\n",
    "* Paste this cell into a terminal of the same directory and go nuts!\n",
    "* Given a word, its meaning and other details will be given"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pds\n",
    "import os\n",
    "import numpy as np\n",
    "import pickle\n",
    "from nltk.corpus import wordnet \n",
    "\n",
    "def get_synonyms(word):\n",
    "    synonyms = []\n",
    "    for syn in wordnet.synsets(word): \n",
    "        for l in syn.lemmas(): \n",
    "            synonyms.append(l.name()) \n",
    "    synonyms = sorted(list(set(synonyms)))\n",
    "    outStr = \"\"\n",
    "    for syn in synonyms:\n",
    "        if syn != word:\n",
    "            outStr += syn\n",
    "            outStr += \", \"\n",
    "    return outStr\n",
    "\n",
    "columns = [\"Source\", \"Word\", \"Meaning\", \"Usage\", \"Correct\", \"Incorrect\", \"Score\"]\n",
    "\n",
    "while(True):\n",
    "    if os.path.exists(\"./dataFrame.p\"):\n",
    "        df = pickle.load(open(\"./dataFrame.p\", \"rb\"))\n",
    "    else:\n",
    "        df = pds.DataFrame(columns=columns)\n",
    "    word = input(\"Enter the word: \").lower()\n",
    "    if word==\"clc\":\n",
    "        os.system(\"clear\")\n",
    "        continue\n",
    "    if len(word)<3:\n",
    "        print(\"\\nDictionary closed!\".upper())\n",
    "        break\n",
    "    cond = (df[\"Word\"] == word)\n",
    "    if cond.any():\n",
    "        index = df[cond].index[0]\n",
    "        row = df.iloc[index]\n",
    "        mean = row[\"Meaning\"]\n",
    "        mean = mean.replace(\"2\" , \"\\n2\")\n",
    "        usage = row[\"Usage\"]\n",
    "        usage = usage.replace(\"2\", \"\\n2\")\n",
    "        print(\"\\nSource : %s : %.2f%%\\n%s = %s\\n\\nEx: %s\\nSynonyms: %s\\n\"%(row[\"Source\"], \n",
    "                                                            row[\"Score\"]*100.0,\n",
    "                                                            row[\"Word\"], \n",
    "                                                            mean, \n",
    "                                                            usage,\n",
    "                                                                       get_synonyms(word)))\n",
    "    else:\n",
    "        print(\"Word '%s' not found in database.\\nPlease check spelling or Enter the word in entry section\\n\"%word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Print the words into a file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "284\n"
     ]
    }
   ],
   "source": [
    "import pandas as pds\n",
    "import os\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "columns = [\"Source\", \"Word\", \"Meaning\", \"Usage\", \"Correct\", \"Incorrect\", \"Score\"]\n",
    "df = pickle.load(open(\"./dataFrame.p\", \"rb\"))\n",
    "cond = (df[\"Score\"]<=0.1)#| ((df[\"Score\"]>0.5) & (df[\"Correct\"]==1))\n",
    "df = df[cond]\n",
    "print(len(df))\n",
    "sorted_df = df.sort_values(by=\"Word\")\n",
    "\n",
    "f = open(\"Words_zero.txt\", \"w\")\n",
    "for i,(word,meaning,usage) in enumerate(zip(sorted_df[\"Word\"], \n",
    "                                       sorted_df[\"Meaning\"], \n",
    "                                       sorted_df[\"Usage\"])):\n",
    "    meaning = meaning.replace(\"2\", \"\\n2\")\n",
    "    usage = usage.replace(\"2\", \"\\n2\")\n",
    "    f.write(\"%d. %s:\\n%s\\nEx:  %s\\n\\n\"%(i+1, word, meaning, usage))\n",
    "#     f.write(\"%d,%s\\n\"%(i+1, word))\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Revise Script V 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/131) ZEALOUS => Score: New%\n",
      "\n",
      "Source : princeton\n",
      "ZEALOUS = avid; marked by active interest and enthusiasm\n",
      "\n",
      "Ex: the council was extremely zealous in the application of the regulations\n",
      "\n",
      "Remember? :: Y/N \n",
      "\n",
      "Ending revision 0/0!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pds\n",
    "import os\n",
    "import numpy as np\n",
    "import pickle\n",
    "from nltk.corpus import wordnet \n",
    "\n",
    "def get_synonyms(word):\n",
    "    synonyms = []\n",
    "    for syn in wordnet.synsets(word): \n",
    "        for l in syn.lemmas(): \n",
    "            synonyms.append(l.name()) \n",
    "    synonyms = sorted(list(set(synonyms)))\n",
    "    outStr = \"\"\n",
    "    for syn in synonyms:\n",
    "        if syn != word:\n",
    "            outStr += syn\n",
    "            outStr += \", \"\n",
    "    return outStr\n",
    "# cond = df[\"Source\"] == \"princeton\"\n",
    "df = pickle.load(open(\"./dataFrame.p\", \"rb\"))\n",
    "temp_df = df.sample(frac=1).reset_index(drop=True)\n",
    "words = []\n",
    "scores = {}\n",
    "\n",
    "for (word, score, src, c, ic) in zip(temp_df[\"Word\"], temp_df[\"Score\"], \n",
    "                              temp_df[\"Source\"], temp_df[\"Correct\"], \n",
    "                              temp_df[\"Incorrect\"]):\n",
    "    if (score<0.61):\n",
    "        words.append(word)\n",
    "        scores[word] = score\n",
    "\n",
    "def key_scores(word):\n",
    "    global scores\n",
    "    return scores[word]\n",
    "\n",
    "sorted_words = sorted(words, key=key_scores)\n",
    "length = len(sorted_words)\n",
    "fin_score = 0\n",
    "\n",
    "for i,word in enumerate(sorted_words):\n",
    "    cond = (df[\"Word\"] == word)\n",
    "    index = df[cond].index[0]\n",
    "    row = df.iloc[index]\n",
    "    mean = row[\"Meaning\"]\n",
    "    mean = mean.replace(\"2\" , \"\\n2\")\n",
    "    usage = row[\"Usage\"]\n",
    "    usage = usage.replace(\"2\", \"\\n2\")\n",
    "    s = row[\"Score\"]\n",
    "    if s == -2:\n",
    "        string = \"New\"\n",
    "    else:\n",
    "        string = str(int(s*100.))\n",
    "    \n",
    "    temp = input(\"%d/%d) %s => Score: %s%%\"%(i+1, length, word.upper(), string))\n",
    "    print(\"\\nSource : %s\\n%s = %s\\n\\nEx: %s\\nSynonyms: %s\"%(row[\"Source\"], \n",
    "                                                row[\"Word\"].upper(), \n",
    "                                                mean, \n",
    "                                                usage, get_synonyms(row[\"Word\"])))\n",
    "    correct = input(\"Remember? :: Y/N \").lower()\n",
    "    if len(correct) == 0:\n",
    "        break\n",
    "     \n",
    "    if (correct[0] == \"y\"):\n",
    "        df.at[index, \"Correct\"] += 1\n",
    "        fin_score += 1\n",
    "    else:\n",
    "        df.at[index, \"Incorrect\"] += 2\n",
    "    os.system(\"clear\")\n",
    "    c = df.at[index, \"Correct\"]\n",
    "    ic = df.at[index, \"Incorrect\"]\n",
    "    \n",
    "    df.at[index, \"Score\"] = float(c)/float(c+ic)\n",
    "    pickle.dump(df, open(\"./dataFrame.p\", \"wb\"))\n",
    "    \n",
    "\n",
    "print(\"\\nEnding revision %d/%d!\"%(fin_score, i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Revise Script V 1.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pds\n",
    "import os\n",
    "import numpy as np\n",
    "import pickle\n",
    "from nltk.corpus import wordnet \n",
    "\n",
    "def get_synonyms(word):\n",
    "    synonyms = []\n",
    "    for syn in wordnet.synsets(word): \n",
    "        for l in syn.lemmas(): \n",
    "            synonyms.append(l.name()) \n",
    "    synonyms = sorted(list(set(synonyms)))\n",
    "    outStr = \"\"\n",
    "    for syn in synonyms:\n",
    "        if syn != word:\n",
    "            outStr += syn\n",
    "            outStr += \", \"\n",
    "    return outStr\n",
    "\n",
    "# cond = df[\"Source\"] == \"princeton\"\n",
    "df = pickle.load(open(\"./dataFrame.p\", \"rb\"))\n",
    "temp_df = df.sample(frac=1).reset_index(drop=True)\n",
    "words = []\n",
    "scores = {}\n",
    "\n",
    "for (word, score, src, c, ic) in zip(temp_df[\"Word\"], temp_df[\"Score\"], \n",
    "                              temp_df[\"Source\"], temp_df[\"Correct\"], \n",
    "                              temp_df[\"Incorrect\"]):\n",
    "    if (score>=0.8):\n",
    "        words.append(word)\n",
    "        scores[word] = score\n",
    "\n",
    "def key_scores(word):\n",
    "    global scores\n",
    "    return scores[word]\n",
    "\n",
    "sorted_words = sorted(words, key=key_scores)\n",
    "length = len(sorted_words)\n",
    "fin_score = 0\n",
    "os.system(\"clear\")\n",
    "print(\"Corpus Length:%d\"%length)\n",
    "groupSize = input(\"Group size for revision: \")\n",
    "if len(groupSize)<2:\n",
    "    groupSize = 30\n",
    "else:\n",
    "    groupSize = int(groupSize)\n",
    "\n",
    "incWords = [\"artifice\",]\n",
    "groupCount = int(np.ceil(length/groupSize))\n",
    "reviseCount = 1\n",
    "\n",
    "for groupIndex in range(groupCount):\n",
    "    currSet = sorted_words[groupIndex*groupSize:(groupIndex+1)*groupSize]\n",
    "    for sweepIndex in range(reviseCount):\n",
    "        np.random.shuffle(currSet)\n",
    "        x = 0\n",
    "        for i, word in enumerate(currSet):\n",
    "            cond = (df[\"Word\"] == word)\n",
    "            index = df[cond].index[0]\n",
    "            row = df.iloc[index]\n",
    "            mean = row[\"Meaning\"]\n",
    "            mean = mean.replace(\"2\" , \"\\n2\")\n",
    "            usage = row[\"Usage\"]\n",
    "            usage = usage.replace(\"2\", \"\\n2\")\n",
    "            s = row[\"Score\"]\n",
    "            if s == -2:\n",
    "                string = \"New\"\n",
    "            else:\n",
    "                string = str(int(s*100.))\n",
    "\n",
    "            temp = input(\"G%d/%d: R%d/%d: W%d/%d) %s => Score: %s%%\"%(groupIndex+1, groupCount, sweepIndex+1,reviseCount,\n",
    "                                                         i+1, groupSize, word.upper(), string))\n",
    "            print(\"\\nSource : %s\\n%s = %s\\n\\nEx: %s\\nSynonyms: %s\"%(row[\"Source\"], \n",
    "                                                        row[\"Word\"].upper(), \n",
    "                                                        mean, \n",
    "                                                        usage, get_synonyms(row[\"Word\"])))\n",
    "            correct = input(\"Remember? :: Y/N \").lower()\n",
    "            if len(correct) == 0:\n",
    "                correct = input(\"Remember? :: Y/N \").lower()\n",
    "\n",
    "            if (correct[0] == \"y\"):\n",
    "                df.at[index, \"Correct\"] += 1\n",
    "                x += 1\n",
    "                fin_score += 1\n",
    "            else:\n",
    "                incWords.append(word)\n",
    "                df.at[index, \"Incorrect\"] += (1+ (sweepIndex//2))\n",
    "            os.system(\"clear\")\n",
    "            c = df.at[index, \"Correct\"]\n",
    "            ic = df.at[index, \"Incorrect\"]\n",
    "\n",
    "            df.at[index, \"Score\"] = float(c)/float(c+ic)\n",
    "            pickle.dump(df, open(\"./dataFrame.p\", \"wb\"))\n",
    "        print(\"Score: G%d/%d :: %d/%d\"%(groupIndex+1, groupCount, x, groupSize))\n",
    "\n",
    "print(\"\\nEnding revision %d/%d!\"%(fin_score, i))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Source</th>\n",
       "      <th>Word</th>\n",
       "      <th>Meaning</th>\n",
       "      <th>Usage</th>\n",
       "      <th>Correct</th>\n",
       "      <th>Incorrect</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>mag_c1</td>\n",
       "      <td>parochial</td>\n",
       "      <td>narrowly restricted in scope or outlook</td>\n",
       "      <td>jasmine was sad to admit it, but her fledgling...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>322</th>\n",
       "      <td>mag_c4</td>\n",
       "      <td>pedantic</td>\n",
       "      <td>marked by a narrow focus on or display of lear...</td>\n",
       "      <td>professor thompson was regarded as an expert i...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Source       Word                                            Meaning  \\\n",
       "192  mag_c1  parochial            narrowly restricted in scope or outlook   \n",
       "322  mag_c4   pedantic  marked by a narrow focus on or display of lear...   \n",
       "\n",
       "                                                 Usage Correct Incorrect  \\\n",
       "192  jasmine was sad to admit it, but her fledgling...       1         2   \n",
       "322  professor thompson was regarded as an expert i...       1         2   \n",
       "\n",
       "        Score  \n",
       "192  0.333333  \n",
       "322  0.333333  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "df = pickle.load(open(\"./dataFrame.p\", \"rb\"))\n",
    "df[(df[\"Meaning\"].str.contains('narrow'))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "721"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "df = pickle.load(open(\"./dataFrame.p\", \"rb\"))\n",
    "# df[\"Meaning\"][df[\"Meaning\"].str.contains(\"negative\")]\n",
    "len(df[(df[\"Score\"]) >= 0.99])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pickle\n",
    "prevScores = scores\n",
    "pKeys = sorted(list(prevScores.keys()))\n",
    "plt.barh([key*100+2 for key in pKeys], [prevScores[key]/len(df[\"Word\"])*100. for key in pKeys], height=2, color=\"r\")\n",
    "\n",
    "df = pickle.load(open(\"./dataFrame.p\", \"rb\"))\n",
    "scores = {}\n",
    "temp = []\n",
    "for word,score in zip(df[\"Word\"], df[\"Score\"]):\n",
    "    if score>=0:\n",
    "        try:\n",
    "            scores[score] += 1\n",
    "        except:\n",
    "            scores[score] = 1\n",
    "        temp.append(score)\n",
    "# plt.hist(temp)\n",
    "# plt.show()\n",
    "\n",
    "        \n",
    "        \n",
    "keys = sorted(list(scores.keys()))\n",
    "for key in keys:\n",
    "    count = scores[key]\n",
    "#     print(\"Score: %.2f -> Fraction: %.2f | %d\"%(key*100.,count/len(df[\"Word\"])*100., count))\n",
    "    \n",
    "from matplotlib import pyplot as plt\n",
    "plt.barh([key*100 for key in keys], [scores[key]/len(df[\"Word\"])*100. for key in keys], height=2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "# df = pickle.load(open(\"./dataFrame.p\", \"rb\"))\n",
    "# scores = {}\n",
    "# for word,mean,usage,score in zip(df[\"Word\"], df[\"Meaning\"], df[\"Usage\"], df[\"Score\"]):\n",
    "#     if score<0.33:\n",
    "#         print(\"%s,%s,%s,%.2f\"%(word,mean,usage,score*100.))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [1,3,5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[5]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[2:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'words' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-45-730c51b3e7e0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mwords\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'words' is not defined"
     ]
    }
   ],
   "source": [
    "words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from nltk.corpus import wordnet\n",
    "# from itertools import product\n",
    "\n",
    "# def isSimilar(word1, word2, th=0.3):\n",
    "#     wordFromList1 = wordnet.synsets(word1)\n",
    "#     wordFromList2 = wordnet.synsets(word2)\n",
    "#     for w1, w2 in product(wordFromList1, wordFromList2):\n",
    "#         d = wordnet.wup_similarity(w1, w2)\n",
    "        \n",
    "#         if (d!=None) and (d>=th):\n",
    "#             return True\n",
    "        \n",
    "# #         if (d == None):\n",
    "# #             return False\n",
    "# #         elif (d!=None) and (d<th):\n",
    "# #             return False\n",
    "#     return False\n",
    "    \n",
    "# def doesBelong(word1, wordList):\n",
    "#     for word2 in wordList:\n",
    "#         if not isSimilar(word1, word2):\n",
    "#             return False\n",
    "#     return True\n",
    "\n",
    "# words = sorted(list(df[\"Word\"].values))\n",
    "# groups = []\n",
    "# for a, word in enumerate(words):\n",
    "#     match = False\n",
    "#     for i,group in enumerate(groups):\n",
    "#         if doesBelong(word, group):\n",
    "#             match = True\n",
    "#             groups[i].append(word)\n",
    "#     groups.append([word])\n",
    "#     if (a+1)%100 == 0:\n",
    "#         print(\"%d/%d\"%(a+1, len(words)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import wordnet\n",
    "from itertools import product\n",
    "\n",
    "def isSimilar(word1, word2, th=0.3):\n",
    "    wordFromList1 = wordnet.synsets(word1)\n",
    "    wordFromList2 = wordnet.synsets(word2)\n",
    "    for w1, w2 in product(wordFromList1, wordFromList2):\n",
    "        d = wordnet.wup_similarity(w1, w2)\n",
    "        \n",
    "        if (d!=None) and (d>=th):\n",
    "            return True\n",
    "        \n",
    "#         if (d == None):\n",
    "#             return False\n",
    "#         elif (d!=None) and (d<th):\n",
    "#             return False\n",
    "    return False\n",
    "\n",
    "isSimilar(\"dirge\", \"sad\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
