{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pds\n",
    "import os\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "columns = [\"Source\", \"Word\", \"Meaning\", \"Usage\", \"Correct\", \"Incorrect\", \"Score\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Enter GRE words into the `Pandas.DataFrame`\n",
    "* Checks if entry has already been made for the same word\n",
    "* To exit the loop give any input of `len(word) < 3`\n",
    "* It is saved after every entry\n",
    "* nltk used to generate synonyms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the source: \n",
      "Source = trivial\n",
      "\n",
      "\n",
      "Enter the Word: protract\n",
      "Enter the Meaning: lengthen in time; cause to be or last longer\n",
      "Enter the Usage: If you have a disagreement with a friend that you continue for weeks and weeks, you are protracting the argument\n",
      "Entry of 'protract' made\n",
      "Current entry count:6\n",
      "\n",
      "Enter the Word: sully\n",
      "Enter the Meaning: make dirty or spotty, as by exposure to air; also used metaphorically\n",
      "Enter the Usage: If you spread false rumors that there's chicken stock in the vegetarian entree at Joe's Diner, you would sully Joe's good reputation\n",
      "Entry of 'sully' made\n",
      "Current entry count:7\n",
      "\n",
      "Enter the Word: foil\n",
      "Enter the Meaning: hinder or prevent (the efforts, plans, or desires) of\n",
      "Enter the Usage: foil your opponent\n",
      "Entry of 'foil' made\n",
      "Current entry count:8\n",
      "\n",
      "Enter the Word: fealty\n",
      "Enter the Meaning: allegiance; the loyalty that citizens owe to their country (or subjects to their sovereign)\n",
      "Enter the Usage: Most school kids pledge their fealty, or allegiance, to the United States of America every morning in homeroom\n",
      "Entry of 'fealty' made\n",
      "Current entry count:9\n",
      "\n",
      "Enter the Word: gentrification\n",
      "Enter the Meaning: the restoration of run-down urban areas by the middle class (resulting in the displacement of low-income residents)\n",
      "Enter the Usage: When a neighborhood goes through gentrification, buildings get makeovers, new businesses open, and many people whoâ€™ve lived there their entire lives must leave because everything gets more expensive\n",
      "Entry of 'gentrification' made\n",
      "Current entry count:10\n",
      "\n",
      "Enter the Word: bonhomie\n",
      "Enter the Meaning: a disposition to be friendly and approachable (easy to talk to)\n",
      "Enter the Usage: ............\n",
      "Entry of 'bonhomie' made\n",
      "Current entry count:11\n",
      "\n",
      "Enter the Word: \n",
      "\n",
      "ENDING THE ENTRY!\n",
      "\n",
      "Word Count in trivial: 11 / 1510\n"
     ]
    }
   ],
   "source": [
    "import pandas as pds\n",
    "import os\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "columns = [\"Source\", \"Word\", \"Meaning\", \n",
    "           \"Usage\", \"Correct\", \"Incorrect\", \"Score\"]\n",
    "\n",
    "def numberOfEntries(df, source):\n",
    "    cond = (df[\"Source\"]==source)\n",
    "    return len(df[\"Word\"][cond])\n",
    "\n",
    "default = \"trivial\"\n",
    "source = input(\"Enter the source: \").lower()\n",
    "if len(source)==0:\n",
    "    source = default.lower()\n",
    "    \n",
    "print(\"Source = %s\\n\\n\"%source)\n",
    "\n",
    "if os.path.exists(\"./dataFrame.p\"):\n",
    "    df = pickle.load(open(\"./dataFrame.p\", \"rb\"))\n",
    "else:\n",
    "    df = pds.DataFrame(columns=columns)\n",
    "\n",
    "while(True):\n",
    "    entry = {\"Source\":source,\n",
    "            \"Correct\":0,\n",
    "            \"Incorrect\":0,\n",
    "            \"Score\":-2.0}\n",
    "    for col in [\"Word\", \"Meaning\", \"Usage\"]:\n",
    "        entry[col] = input(\"Enter the %s: \"%col).lower()\n",
    "        if len(entry[col])<3:\n",
    "            entry = {\"Source\":\"NULL\"}\n",
    "            break\n",
    "    if entry[\"Source\"] != \"NULL\":\n",
    "        cond = (df[\"Word\"] == entry[\"Word\"])\n",
    "        if cond.any():\n",
    "            index = df[cond].index[0]\n",
    "            row = df.iloc[index]\n",
    "            print(\"\\nWord %s exists from %s\\n\\t%s = %s\\n\\tEx: %s\\n\"%(row[\"Word\"], row[\"Source\"], \n",
    "                                                               row[\"Word\"], row[\"Meaning\"], \n",
    "                                                               row[\"Usage\"]))\n",
    "            cmd = input(\"Do you wish to replace? Y/N \").lower()\n",
    "            if cmd=='y':\n",
    "                df.at[index, \"Meaning\"] = entry[\"Meaning\"]\n",
    "                df.at[index, \"Usage\"] = entry[\"Usage\"]\n",
    "                print(\"Modification for %s is done\"%(entry[\"Word\"]))\n",
    "                pickle.dump(df, open(\"./dataFrame.p\", \"wb\"))\n",
    "        else:\n",
    "            df = df.append(entry, ignore_index=True, )\n",
    "            pickle.dump(df, open(\"./dataFrame.p\", \"wb\"))\n",
    "            print(\"Entry of '%s' made\\nCurrent entry count:%d\\n\"%(entry[\"Word\"], numberOfEntries(df, source)))\n",
    "    else:\n",
    "        print(\"\\nEnding the entry!\".upper())\n",
    "        break\n",
    "\n",
    "print(\"\\nWord Count in %s: %d / %d\"%(source, numberOfEntries(df, source), len(df)-2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dictionary implementation\n",
    "* Paste this cell into a terminal of the same directory and go nuts!\n",
    "* Given a word, its meaning and other details will be given\n",
    "* nltk used to generate synonyms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pds\n",
    "import os\n",
    "import numpy as np\n",
    "import pickle\n",
    "from nltk.corpus import wordnet \n",
    "\n",
    "def get_synonyms(word):\n",
    "    synonyms = []\n",
    "    for syn in wordnet.synsets(word): \n",
    "        for l in syn.lemmas(): \n",
    "            synonyms.append(l.name()) \n",
    "    synonyms = sorted(list(set(synonyms)))\n",
    "    outStr = \"\"\n",
    "    for syn in synonyms:\n",
    "        if syn != word:\n",
    "            outStr += syn\n",
    "            outStr += \", \"\n",
    "    return outStr\n",
    "\n",
    "columns = [\"Source\", \"Word\", \"Meaning\", \"Usage\", \"Correct\", \"Incorrect\", \"Score\"]\n",
    "\n",
    "while(True):\n",
    "    if os.path.exists(\"./dataFrame.p\"):\n",
    "        df = pickle.load(open(\"./dataFrame.p\", \"rb\"))\n",
    "    else:\n",
    "        df = pds.DataFrame(columns=columns)\n",
    "    word = input(\"Enter the word: \").lower()\n",
    "    if word==\"clc\":\n",
    "        os.system(\"clear\")\n",
    "        continue\n",
    "    if len(word)<3:\n",
    "        print(\"\\nDictionary closed!\".upper())\n",
    "        break\n",
    "    cond = (df[\"Word\"] == word)\n",
    "    if cond.any():\n",
    "        index = df[cond].index[0]\n",
    "        row = df.iloc[index]\n",
    "        mean = row[\"Meaning\"]\n",
    "        mean = mean.replace(\"2\" , \"\\n2\")\n",
    "        usage = row[\"Usage\"]\n",
    "        usage = usage.replace(\"2\", \"\\n2\")\n",
    "        print(\"\\nSource : %s : %.2f%%\\n%s = %s\\n\\nEx: %s\\nSynonyms: %s\\n\"%(row[\"Source\"], \n",
    "                                                            row[\"Score\"]*100.0,\n",
    "                                                            row[\"Word\"], \n",
    "                                                            mean, \n",
    "                                                            usage,\n",
    "                                                                       get_synonyms(word)))\n",
    "    else:\n",
    "        print(\"Word '%s' not found in database.\\nPlease check spelling or Enter the word in entry section\\n\"%word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Print the words into a file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "284\n"
     ]
    }
   ],
   "source": [
    "import pandas as pds\n",
    "import os\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "columns = [\"Source\", \"Word\", \"Meaning\", \"Usage\", \"Correct\", \"Incorrect\", \"Score\"]\n",
    "df = pickle.load(open(\"./dataFrame.p\", \"rb\"))\n",
    "cond = (df[\"Score\"]<=0.1)#| ((df[\"Score\"]>0.5) & (df[\"Correct\"]==1))\n",
    "df = df[cond]\n",
    "print(len(df))\n",
    "sorted_df = df.sort_values(by=\"Word\")\n",
    "\n",
    "f = open(\"Words_zero.txt\", \"w\")\n",
    "for i,(word,meaning,usage) in enumerate(zip(sorted_df[\"Word\"], \n",
    "                                       sorted_df[\"Meaning\"], \n",
    "                                       sorted_df[\"Usage\"])):\n",
    "    meaning = meaning.replace(\"2\", \"\\n2\")\n",
    "    usage = usage.replace(\"2\", \"\\n2\")\n",
    "    f.write(\"%d. %s:\\n%s\\nEx:  %s\\n\\n\"%(i+1, word, meaning, usage))\n",
    "#     f.write(\"%d,%s\\n\"%(i+1, word))\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Revise Script V 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/131) ZEALOUS => Score: New%\n",
      "\n",
      "Source : princeton\n",
      "ZEALOUS = avid; marked by active interest and enthusiasm\n",
      "\n",
      "Ex: the council was extremely zealous in the application of the regulations\n",
      "\n",
      "Remember? :: Y/N \n",
      "\n",
      "Ending revision 0/0!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pds\n",
    "import os\n",
    "import numpy as np\n",
    "import pickle\n",
    "from nltk.corpus import wordnet \n",
    "\n",
    "def get_synonyms(word):\n",
    "    synonyms = []\n",
    "    for syn in wordnet.synsets(word): \n",
    "        for l in syn.lemmas(): \n",
    "            synonyms.append(l.name()) \n",
    "    synonyms = sorted(list(set(synonyms)))\n",
    "    outStr = \"\"\n",
    "    for syn in synonyms:\n",
    "        if syn != word:\n",
    "            outStr += syn\n",
    "            outStr += \", \"\n",
    "    return outStr\n",
    "# cond = df[\"Source\"] == \"princeton\"\n",
    "df = pickle.load(open(\"./dataFrame.p\", \"rb\"))\n",
    "temp_df = df.sample(frac=1).reset_index(drop=True)\n",
    "words = []\n",
    "scores = {}\n",
    "\n",
    "for (word, score, src, c, ic) in zip(temp_df[\"Word\"], temp_df[\"Score\"], \n",
    "                              temp_df[\"Source\"], temp_df[\"Correct\"], \n",
    "                              temp_df[\"Incorrect\"]):\n",
    "    if (score<0.61):\n",
    "        words.append(word)\n",
    "        scores[word] = score\n",
    "\n",
    "def key_scores(word):\n",
    "    global scores\n",
    "    return scores[word]\n",
    "\n",
    "sorted_words = sorted(words, key=key_scores)\n",
    "length = len(sorted_words)\n",
    "fin_score = 0\n",
    "\n",
    "for i,word in enumerate(sorted_words):\n",
    "    cond = (df[\"Word\"] == word)\n",
    "    index = df[cond].index[0]\n",
    "    row = df.iloc[index]\n",
    "    mean = row[\"Meaning\"]\n",
    "    mean = mean.replace(\"2\" , \"\\n2\")\n",
    "    usage = row[\"Usage\"]\n",
    "    usage = usage.replace(\"2\", \"\\n2\")\n",
    "    s = row[\"Score\"]\n",
    "    if s == -2:\n",
    "        string = \"New\"\n",
    "    else:\n",
    "        string = str(int(s*100.))\n",
    "    \n",
    "    temp = input(\"%d/%d) %s => Score: %s%%\"%(i+1, length, word.upper(), string))\n",
    "    print(\"\\nSource : %s\\n%s = %s\\n\\nEx: %s\\nSynonyms: %s\"%(row[\"Source\"], \n",
    "                                                row[\"Word\"].upper(), \n",
    "                                                mean, \n",
    "                                                usage, get_synonyms(row[\"Word\"])))\n",
    "    correct = input(\"Remember? :: Y/N \").lower()\n",
    "    if len(correct) == 0:\n",
    "        break\n",
    "     \n",
    "    if (correct[0] == \"y\"):\n",
    "        df.at[index, \"Correct\"] += 1\n",
    "        fin_score += 1\n",
    "    else:\n",
    "        df.at[index, \"Incorrect\"] += 2\n",
    "    os.system(\"clear\")\n",
    "    c = df.at[index, \"Correct\"]\n",
    "    ic = df.at[index, \"Incorrect\"]\n",
    "    \n",
    "    df.at[index, \"Score\"] = float(c)/float(c+ic)\n",
    "    pickle.dump(df, open(\"./dataFrame.p\", \"wb\"))\n",
    "    \n",
    "\n",
    "print(\"\\nEnding revision %d/%d!\"%(fin_score, i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Revise Script V 1.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corpus Length:829\n",
      "Group size for revision: \n",
      "G1/28: R1/2: W1/30) INCLEMENT => Score: 50%\n",
      "\n",
      "Source : mag_b3\n",
      "INCLEMENT = 1. (adj) (of weather) unpleasant, stormy \n",
      "2. (adj) used of persons or behavior; showing no mercy\n",
      "\n",
      "Ex: 1. after a week of inclement weather, we finally are able to go outside and enjoy the sun; \n",
      "2. marcus aurelius, though a fair man, was inclement to christians during his reign, persecuting them violently\n",
      "Synonyms: \n",
      "Remember? :: Y/N \n",
      "Remember? :: Y/N \n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "string index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-4f01f6f1ed73>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     80\u001b[0m                 \u001b[0mcorrect\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Remember? :: Y/N \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mcorrect\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"y\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     83\u001b[0m                 \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Correct\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m                 \u001b[0mx\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: string index out of range"
     ]
    }
   ],
   "source": [
    "import pandas as pds\n",
    "import os\n",
    "import numpy as np\n",
    "import pickle\n",
    "from nltk.corpus import wordnet \n",
    "\n",
    "def get_synonyms(word):\n",
    "    synonyms = []\n",
    "    for syn in wordnet.synsets(word): \n",
    "        for l in syn.lemmas(): \n",
    "            synonyms.append(l.name()) \n",
    "    synonyms = sorted(list(set(synonyms)))\n",
    "    outStr = \"\"\n",
    "    for syn in synonyms:\n",
    "        if syn != word:\n",
    "            outStr += syn\n",
    "            outStr += \", \"\n",
    "    return outStr\n",
    "\n",
    "# cond = df[\"Source\"] == \"princeton\"\n",
    "df = pickle.load(open(\"./dataFrame.p\", \"rb\"))\n",
    "temp_df = df.sample(frac=1).reset_index(drop=True)\n",
    "words = []\n",
    "scores = {}\n",
    "\n",
    "for (word, score, src, c, ic) in zip(temp_df[\"Word\"], temp_df[\"Score\"], \n",
    "                              temp_df[\"Source\"], temp_df[\"Correct\"], \n",
    "                              temp_df[\"Incorrect\"]):\n",
    "    if ((\"mag_a\" not in src) and (\"barrons\" not in src)):\n",
    "        words.append(word)\n",
    "        scores[word] = score\n",
    "\n",
    "def key_scores(word):\n",
    "    global scores\n",
    "    return scores[word]\n",
    "\n",
    "sorted_words = sorted(words, key=key_scores)\n",
    "length = len(sorted_words)\n",
    "fin_score = 0\n",
    "os.system(\"clear\")\n",
    "print(\"Corpus Length:%d\"%length)\n",
    "groupSize = input(\"Group size for revision: \")\n",
    "if len(groupSize)<2:\n",
    "    groupSize = 30\n",
    "else:\n",
    "    groupSize = int(groupSize)\n",
    "\n",
    "incWords = []\n",
    "groupCount = int(np.ceil(length/groupSize))\n",
    "reviseCount = 2\n",
    "\n",
    "for groupIndex in range(groupCount):\n",
    "    currSet = sorted_words[groupIndex*groupSize:(groupIndex+1)*groupSize]\n",
    "    for sweepIndex in range(reviseCount):\n",
    "        np.random.shuffle(currSet)\n",
    "        x = 0\n",
    "        tempIncWords = []\n",
    "        for i, word in enumerate(currSet):\n",
    "            cond = (df[\"Word\"] == word)\n",
    "            index = df[cond].index[0]\n",
    "            row = df.iloc[index]\n",
    "            mean = row[\"Meaning\"]\n",
    "            mean = mean.replace(\"2\" , \"\\n2\")\n",
    "            usage = row[\"Usage\"]\n",
    "            usage = usage.replace(\"2\", \"\\n2\")\n",
    "            s = row[\"Score\"]\n",
    "            if s == -2:\n",
    "                string = \"New\"\n",
    "            else:\n",
    "                string = str(int(s*100.))\n",
    "\n",
    "            temp = input(\"G%d/%d: R%d/%d: W%d/%d) %s => Score: %s%%\"%(groupIndex+1, groupCount, sweepIndex+1,reviseCount,\n",
    "                                                         i+1, groupSize, word.upper(), string))\n",
    "            print(\"\\nSource : %s\\n%s = %s\\n\\nEx: %s\\nSynonyms: %s\"%(row[\"Source\"], \n",
    "                                                        row[\"Word\"].upper(), \n",
    "                                                        mean, \n",
    "                                                        usage, get_synonyms(row[\"Word\"])))\n",
    "            correct = input(\"Remember? :: Y/N \").lower()\n",
    "            if len(correct) == 0:\n",
    "                correct = input(\"Remember? :: Y/N \").lower()\n",
    "\n",
    "            if (correct[0] == \"y\"):\n",
    "                df.at[index, \"Correct\"] += 1\n",
    "                x += 1\n",
    "                fin_score += 1\n",
    "            elif correct[0] == \"s\":\n",
    "                sweepIndex += 1\n",
    "                break\n",
    "            else:\n",
    "                if word not in incWords:\n",
    "                    incWords.append(word)\n",
    "                tempIncWords.append(word)\n",
    "                df.at[index, \"Incorrect\"] += (1+ (sweepIndex//2))\n",
    "            os.system(\"clear\")\n",
    "            c = df.at[index, \"Correct\"]\n",
    "            ic = df.at[index, \"Incorrect\"]\n",
    "\n",
    "            df.at[index, \"Score\"] = float(c)/float(c+ic)\n",
    "            pickle.dump(df, open(\"./dataFrame.p\", \"wb\"))\n",
    "        print(tempIncWords)\n",
    "        print(\"Score: G%d/%d :: %d/%d\"%(groupIndex+1, groupCount, x, groupSize))\n",
    "\n",
    "print(\"\\nEnding revision %d/%d!\"%(fin_score, length*reviseCount))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "348"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "df = pickle.load(open(\"./dataFrame.p\", \"rb\"))\n",
    "len(df[~((df[\"Source\"].str.contains('mag_a')) | (df[\"Source\"].str.contains(\"barrons\"))) & ((df[\"Score\"] <= 0.8))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Source</th>\n",
       "      <th>Word</th>\n",
       "      <th>Meaning</th>\n",
       "      <th>Usage</th>\n",
       "      <th>Correct</th>\n",
       "      <th>Incorrect</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>mag_b5</td>\n",
       "      <td>exemplify</td>\n",
       "      <td>1. (verb) to be a typical example of; 2. (verb...</td>\n",
       "      <td>a dish that exemplifies french cuisine; presen...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>mag_b5</td>\n",
       "      <td>exasperate</td>\n",
       "      <td>to irritate or frustrate intensely</td>\n",
       "      <td>as a child, i exasperated my mother with never...</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0.714286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>MAG_B7</td>\n",
       "      <td>excruciating</td>\n",
       "      <td>extremely painful</td>\n",
       "      <td>after the boulder rolled a couple of feet, pin...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>mag_c1</td>\n",
       "      <td>extant</td>\n",
       "      <td>still in existence (usually refers to documents)</td>\n",
       "      <td>despite many bookstores closing, experts predi...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219</th>\n",
       "      <td>mag_c2</td>\n",
       "      <td>exacerbate</td>\n",
       "      <td>make worse</td>\n",
       "      <td>her sleeplessness exacerbated her cold--when s...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>321</th>\n",
       "      <td>mag_c4</td>\n",
       "      <td>expound</td>\n",
       "      <td>add details or explanation; clarify the meanin...</td>\n",
       "      <td>the ceo refused to expound on the decision to ...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>327</th>\n",
       "      <td>mag_c4</td>\n",
       "      <td>exacting</td>\n",
       "      <td>requiring and demanding accuracy</td>\n",
       "      <td>though his childhood piano teacher was so exac...</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>334</th>\n",
       "      <td>mag_c4</td>\n",
       "      <td>exonerate</td>\n",
       "      <td>pronounce not guilty of criminal charges</td>\n",
       "      <td>the document clearly indicated that nick was o...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>339</th>\n",
       "      <td>mag_c4</td>\n",
       "      <td>exalt</td>\n",
       "      <td>praise or glorify</td>\n",
       "      <td>the teenagers exalted the rock star, covering ...</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0.857143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>512</th>\n",
       "      <td>mag_b2</td>\n",
       "      <td>extenuating</td>\n",
       "      <td>making less guilty or more forgivable</td>\n",
       "      <td>the jury was hardly moved by the manâ€™s plea th...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>529</th>\n",
       "      <td>mag_b2</td>\n",
       "      <td>exhort</td>\n",
       "      <td>to strongly urge on; encourage</td>\n",
       "      <td>nelsonâ€™s parents exhorted him to study medicin...</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0.857143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>663</th>\n",
       "      <td>princeton</td>\n",
       "      <td>exculpate</td>\n",
       "      <td>exonerate</td>\n",
       "      <td>the article exculpated the mayor</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>664</th>\n",
       "      <td>princeton</td>\n",
       "      <td>exigent</td>\n",
       "      <td>urgent; pressing; demanding</td>\n",
       "      <td>the exigent demand of her contemporaries' musi...</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0.857143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>665</th>\n",
       "      <td>princeton</td>\n",
       "      <td>extemporaneous</td>\n",
       "      <td>spoken or done without preparation</td>\n",
       "      <td>an extemporaneous speech</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0.857143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>729</th>\n",
       "      <td>mag_a1</td>\n",
       "      <td>exegesis</td>\n",
       "      <td>noun: critical explanation or analysis, especi...</td>\n",
       "      <td>the bible is fertile ground for exegesisâ€”over ...</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>731</th>\n",
       "      <td>mag_a1</td>\n",
       "      <td>expansive</td>\n",
       "      <td>adjective: communicative, and prone to talking...</td>\n",
       "      <td>after a few sips of cognac, the octogenarian s...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>745</th>\n",
       "      <td>mag_a1</td>\n",
       "      <td>expunge</td>\n",
       "      <td>obliterate or remove completely (something unw...</td>\n",
       "      <td>when i turned 18, all of the shoplifting and j...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>766</th>\n",
       "      <td>mag_a7</td>\n",
       "      <td>extrapolate</td>\n",
       "      <td>draw from specific cases for more general cases</td>\n",
       "      <td>by extrapolating from the data on the past thr...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>899</th>\n",
       "      <td>mag_a2</td>\n",
       "      <td>expurgate</td>\n",
       "      <td>verb: to remove objectionable material</td>\n",
       "      <td>the censor expurgated every reference to sex a...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.833333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>929</th>\n",
       "      <td>mag_a2</td>\n",
       "      <td>execrate</td>\n",
       "      <td>verb: to curse and hiss at</td>\n",
       "      <td>though the new sitcom did decently in the rati...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.833333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>935</th>\n",
       "      <td>mag_a2</td>\n",
       "      <td>excoriate</td>\n",
       "      <td>verb: to criticize very harshly</td>\n",
       "      <td>entrusted with the prototype to his companyâ€™s ...</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0.857143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1073</th>\n",
       "      <td>mag_a5</td>\n",
       "      <td>exemplar</td>\n",
       "      <td>something to be imitated</td>\n",
       "      <td>lena's homework is on the wall because it is a...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1104</th>\n",
       "      <td>mag_a7</td>\n",
       "      <td>exiguity</td>\n",
       "      <td>noun: the quality of being meager</td>\n",
       "      <td>after two months at sea, the exiguity of the s...</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1113</th>\n",
       "      <td>mag_a7</td>\n",
       "      <td>exorbitant</td>\n",
       "      <td>adjective: greatly exceeding bounds of reason ...</td>\n",
       "      <td>shelley made one exorbitant purchase after ano...</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1223</th>\n",
       "      <td>barrons800</td>\n",
       "      <td>execrable</td>\n",
       "      <td>unequivocally detestable</td>\n",
       "      <td>execrable crimes</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.833333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1224</th>\n",
       "      <td>barrons800</td>\n",
       "      <td>existential</td>\n",
       "      <td>having to do with existence</td>\n",
       "      <td>an existential moment of choice</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1225</th>\n",
       "      <td>barrons800</td>\n",
       "      <td>expatiate</td>\n",
       "      <td>add details, as to an account or idea; clarify...</td>\n",
       "      <td>she expatiated on working-class novelists</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1226</th>\n",
       "      <td>barrons800</td>\n",
       "      <td>expatriate</td>\n",
       "      <td>to send into exile</td>\n",
       "      <td>we expatriated the prisoners of war immediately</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1227</th>\n",
       "      <td>barrons800</td>\n",
       "      <td>expiate</td>\n",
       "      <td>make amends or reparation for (guilt or wrongd...</td>\n",
       "      <td>their sins must be expiated by sacrifice</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0.142857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1228</th>\n",
       "      <td>barrons800</td>\n",
       "      <td>explicate</td>\n",
       "      <td>elaborate, as of theories and hypotheses</td>\n",
       "      <td>an attempt to explicate the relationship betwe...</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1229</th>\n",
       "      <td>barrons800</td>\n",
       "      <td>expository</td>\n",
       "      <td>intended to explain or describe something</td>\n",
       "      <td>an expository prologue</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1230</th>\n",
       "      <td>barrons800</td>\n",
       "      <td>extirpate</td>\n",
       "      <td>eradicate or destroy completely</td>\n",
       "      <td>timber wolves were extirpated from new england...</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1231</th>\n",
       "      <td>barrons800</td>\n",
       "      <td>extraneous</td>\n",
       "      <td>irrelevant or unrelated to the subject being d...</td>\n",
       "      <td>one is obliged to wade through many pages of e...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1232</th>\n",
       "      <td>barrons800</td>\n",
       "      <td>extrinsic</td>\n",
       "      <td>not forming an essential part of a thing or ar...</td>\n",
       "      <td>an extrinsic evidence</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.833333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Source            Word  \\\n",
       "10        mag_b5       exemplify   \n",
       "20        mag_b5      exasperate   \n",
       "130       MAG_B7    excruciating   \n",
       "163       mag_c1          extant   \n",
       "219       mag_c2      exacerbate   \n",
       "321       mag_c4         expound   \n",
       "327       mag_c4        exacting   \n",
       "334       mag_c4       exonerate   \n",
       "339       mag_c4           exalt   \n",
       "512       mag_b2     extenuating   \n",
       "529       mag_b2          exhort   \n",
       "663    princeton       exculpate   \n",
       "664    princeton         exigent   \n",
       "665    princeton  extemporaneous   \n",
       "729       mag_a1        exegesis   \n",
       "731       mag_a1       expansive   \n",
       "745       mag_a1         expunge   \n",
       "766       mag_a7     extrapolate   \n",
       "899       mag_a2       expurgate   \n",
       "929       mag_a2        execrate   \n",
       "935       mag_a2       excoriate   \n",
       "1073      mag_a5        exemplar   \n",
       "1104      mag_a7        exiguity   \n",
       "1113      mag_a7      exorbitant   \n",
       "1223  barrons800       execrable   \n",
       "1224  barrons800     existential   \n",
       "1225  barrons800       expatiate   \n",
       "1226  barrons800      expatriate   \n",
       "1227  barrons800         expiate   \n",
       "1228  barrons800       explicate   \n",
       "1229  barrons800      expository   \n",
       "1230  barrons800       extirpate   \n",
       "1231  barrons800      extraneous   \n",
       "1232  barrons800       extrinsic   \n",
       "\n",
       "                                                Meaning  \\\n",
       "10    1. (verb) to be a typical example of; 2. (verb...   \n",
       "20                   to irritate or frustrate intensely   \n",
       "130                                   extremely painful   \n",
       "163    still in existence (usually refers to documents)   \n",
       "219                                          make worse   \n",
       "321   add details or explanation; clarify the meanin...   \n",
       "327                    requiring and demanding accuracy   \n",
       "334            pronounce not guilty of criminal charges   \n",
       "339                                   praise or glorify   \n",
       "512               making less guilty or more forgivable   \n",
       "529                      to strongly urge on; encourage   \n",
       "663                                           exonerate   \n",
       "664                         urgent; pressing; demanding   \n",
       "665                  spoken or done without preparation   \n",
       "729   noun: critical explanation or analysis, especi...   \n",
       "731   adjective: communicative, and prone to talking...   \n",
       "745   obliterate or remove completely (something unw...   \n",
       "766     draw from specific cases for more general cases   \n",
       "899              verb: to remove objectionable material   \n",
       "929                          verb: to curse and hiss at   \n",
       "935                     verb: to criticize very harshly   \n",
       "1073                           something to be imitated   \n",
       "1104                  noun: the quality of being meager   \n",
       "1113  adjective: greatly exceeding bounds of reason ...   \n",
       "1223                           unequivocally detestable   \n",
       "1224                        having to do with existence   \n",
       "1225  add details, as to an account or idea; clarify...   \n",
       "1226                                 to send into exile   \n",
       "1227  make amends or reparation for (guilt or wrongd...   \n",
       "1228           elaborate, as of theories and hypotheses   \n",
       "1229          intended to explain or describe something   \n",
       "1230                    eradicate or destroy completely   \n",
       "1231  irrelevant or unrelated to the subject being d...   \n",
       "1232  not forming an essential part of a thing or ar...   \n",
       "\n",
       "                                                  Usage Correct Incorrect  \\\n",
       "10    a dish that exemplifies french cuisine; presen...       3         0   \n",
       "20    as a child, i exasperated my mother with never...       5         2   \n",
       "130   after the boulder rolled a couple of feet, pin...       3         0   \n",
       "163   despite many bookstores closing, experts predi...       3         0   \n",
       "219   her sleeplessness exacerbated her cold--when s...       4         1   \n",
       "321   the ceo refused to expound on the decision to ...       4         1   \n",
       "327   though his childhood piano teacher was so exac...       4         0   \n",
       "334   the document clearly indicated that nick was o...       3         0   \n",
       "339   the teenagers exalted the rock star, covering ...       6         1   \n",
       "512   the jury was hardly moved by the manâ€™s plea th...       4         1   \n",
       "529   nelsonâ€™s parents exhorted him to study medicin...       6         1   \n",
       "663                    the article exculpated the mayor       4         0   \n",
       "664   the exigent demand of her contemporaries' musi...       6         1   \n",
       "665                            an extemporaneous speech       6         1   \n",
       "729   the bible is fertile ground for exegesisâ€”over ...       2         3   \n",
       "731   after a few sips of cognac, the octogenarian s...       1         2   \n",
       "745   when i turned 18, all of the shoplifting and j...       1         2   \n",
       "766   by extrapolating from the data on the past thr...       3         0   \n",
       "899   the censor expurgated every reference to sex a...       5         1   \n",
       "929   though the new sitcom did decently in the rati...       5         1   \n",
       "935   entrusted with the prototype to his companyâ€™s ...       6         1   \n",
       "1073  lena's homework is on the wall because it is a...       3         0   \n",
       "1104  after two months at sea, the exiguity of the s...       2         3   \n",
       "1113  shelley made one exorbitant purchase after ano...       2         3   \n",
       "1223                                   execrable crimes       5         1   \n",
       "1224                    an existential moment of choice       3         0   \n",
       "1225          she expatiated on working-class novelists       2         4   \n",
       "1226    we expatriated the prisoners of war immediately       2         3   \n",
       "1227           their sins must be expiated by sacrifice       1         6   \n",
       "1228  an attempt to explicate the relationship betwe...       2         3   \n",
       "1229                             an expository prologue       1         2   \n",
       "1230  timber wolves were extirpated from new england...       2         3   \n",
       "1231  one is obliged to wade through many pages of e...       4         1   \n",
       "1232                              an extrinsic evidence       5         1   \n",
       "\n",
       "         Score  \n",
       "10    1.000000  \n",
       "20    0.714286  \n",
       "130   1.000000  \n",
       "163   1.000000  \n",
       "219   0.800000  \n",
       "321   0.800000  \n",
       "327   1.000000  \n",
       "334   1.000000  \n",
       "339   0.857143  \n",
       "512   0.800000  \n",
       "529   0.857143  \n",
       "663   1.000000  \n",
       "664   0.857143  \n",
       "665   0.857143  \n",
       "729   0.400000  \n",
       "731   0.333333  \n",
       "745   0.333333  \n",
       "766   1.000000  \n",
       "899   0.833333  \n",
       "929   0.833333  \n",
       "935   0.857143  \n",
       "1073  1.000000  \n",
       "1104  0.400000  \n",
       "1113  0.400000  \n",
       "1223  0.833333  \n",
       "1224  1.000000  \n",
       "1225  0.333333  \n",
       "1226  0.400000  \n",
       "1227  0.142857  \n",
       "1228  0.400000  \n",
       "1229  0.333333  \n",
       "1230  0.400000  \n",
       "1231  0.800000  \n",
       "1232  0.833333  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df[\"Word\"].str.startswith(\"ex\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "105"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "df = pickle.load(open(\"./dataFrame.p\", \"rb\"))\n",
    "# df[\"Meaning\"][df[\"Meaning\"].str.contains(\"negative\")]\n",
    "len(df[(df[\"Score\"] < 0.5) & (df[\"Source\"].str.contains(\"barrons\")) ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'scores' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-8a4726988a86>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mprevScores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mpKeys\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprevScores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbarh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpKeys\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mprevScores\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Word\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m100.\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpKeys\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"r\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'scores' is not defined"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "from matplotlib import pyplot as plt\n",
    "prevScores = scores\n",
    "pKeys = sorted(list(prevScores.keys()))\n",
    "plt.barh([key*100+2 for key in pKeys], [prevScores[key]/len(df[\"Word\"])*100. for key in pKeys], height=2, color=\"r\")\n",
    "\n",
    "df = pickle.load(open(\"./dataFrame.p\", \"rb\"))\n",
    "scores = {}\n",
    "temp = []\n",
    "for word,score in zip(df[\"Word\"], df[\"Score\"]):\n",
    "    if score>=0:\n",
    "        try:\n",
    "            scores[score] += 1\n",
    "        except:\n",
    "            scores[score] = 1\n",
    "        temp.append(score)\n",
    "# plt.hist(temp)\n",
    "# plt.show()\n",
    "\n",
    "        \n",
    "        \n",
    "keys = sorted(list(scores.keys()))\n",
    "for key in keys:\n",
    "    count = scores[key]\n",
    "#     print(\"Score: %.2f -> Fraction: %.2f | %d\"%(key*100.,count/len(df[\"Word\"])*100., count))\n",
    "    \n",
    "from matplotlib import pyplot as plt\n",
    "plt.barh([key*100 for key in keys], [scores[key]/len(df[\"Word\"])*100. for key in keys], height=2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "# df = pickle.load(open(\"./dataFrame.p\", \"rb\"))\n",
    "# scores = {}\n",
    "# for word,mean,usage,score in zip(df[\"Word\"], df[\"Meaning\"], df[\"Usage\"], df[\"Score\"]):\n",
    "#     if score<0.33:\n",
    "#         print(\"%s,%s,%s,%.2f\"%(word,mean,usage,score*100.))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [1,3,5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[5]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[2:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'words' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-45-730c51b3e7e0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mwords\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'words' is not defined"
     ]
    }
   ],
   "source": [
    "words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from nltk.corpus import wordnet\n",
    "# from itertools import product\n",
    "\n",
    "# def isSimilar(word1, word2, th=0.3):\n",
    "#     wordFromList1 = wordnet.synsets(word1)\n",
    "#     wordFromList2 = wordnet.synsets(word2)\n",
    "#     for w1, w2 in product(wordFromList1, wordFromList2):\n",
    "#         d = wordnet.wup_similarity(w1, w2)\n",
    "        \n",
    "#         if (d!=None) and (d>=th):\n",
    "#             return True\n",
    "        \n",
    "# #         if (d == None):\n",
    "# #             return False\n",
    "# #         elif (d!=None) and (d<th):\n",
    "# #             return False\n",
    "#     return False\n",
    "    \n",
    "# def doesBelong(word1, wordList):\n",
    "#     for word2 in wordList:\n",
    "#         if not isSimilar(word1, word2):\n",
    "#             return False\n",
    "#     return True\n",
    "\n",
    "# words = sorted(list(df[\"Word\"].values))\n",
    "# groups = []\n",
    "# for a, word in enumerate(words):\n",
    "#     match = False\n",
    "#     for i,group in enumerate(groups):\n",
    "#         if doesBelong(word, group):\n",
    "#             match = True\n",
    "#             groups[i].append(word)\n",
    "#     groups.append([word])\n",
    "#     if (a+1)%100 == 0:\n",
    "#         print(\"%d/%d\"%(a+1, len(words)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import wordnet\n",
    "from itertools import product\n",
    "\n",
    "def isSimilar(word1, word2, th=0.3):\n",
    "    wordFromList1 = wordnet.synsets(word1)\n",
    "    wordFromList2 = wordnet.synsets(word2)\n",
    "    for w1, w2 in product(wordFromList1, wordFromList2):\n",
    "        d = wordnet.wup_similarity(w1, w2)\n",
    "        \n",
    "        if (d!=None) and (d>=th):\n",
    "            return True\n",
    "        \n",
    "#         if (d == None):\n",
    "#             return False\n",
    "#         elif (d!=None) and (d<th):\n",
    "#             return False\n",
    "    return False\n",
    "\n",
    "isSimilar(\"dirge\", \"sad\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
